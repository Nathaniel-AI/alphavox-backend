import logging
import json
from datetime import datetime, timedelta
import numpy as np
from collections import Counter
from app_init import db
from models import (
    User, UserInteraction, CommunicationProfile, UserPreference,
    LearningMilestone, LearningTemplate, LearningSession, SkillLevel, RecognitionFeedback
)

# Setup logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("learning_analytics")

class LearningAnalytics:
    """
    Analytics engine that tracks and analyzes user progress over time.
    Used for the caregiver dashboard to visualize improvement.
    """
    
    def __init__(self, user_id=None):
        self.user_id = user_id
        logger.info(f"Initializing LearningAnalytics for user {user_id}")
    
    def get_interaction_frequency(self, period='week'):
        """
        Get interaction frequency over time.
        
        Args:
            period (str): 'week', 'month', or 'year'
            
        Returns:
            dict: Labels and data for charting
        """
        if not self.user_id:
            return {'labels': [], 'data': []}
        
        # Define time period
        if period == 'week':
            start_date = datetime.now() - timedelta(days=7)
            date_format = '%A'  # Day name
            groupby_format = '%w'  # Day of week (0-6)
        elif period == 'month':
            start_date = datetime.now() - timedelta(days=30)
            date_format = 'Week %U'  # Week number
            groupby_format = '%U'  # Week of year
        elif period == 'year':
            start_date = datetime.now() - timedelta(days=365)
            date_format = '%b'  # Month abbreviation
            groupby_format = '%m'  # Month (01-12)
        else:
            return {'labels': [], 'data': []}
        
        # Get interactions for the user
        interactions = UserInteraction.query.filter(
            UserInteraction.user_id == self.user_id,
            UserInteraction.timestamp >= start_date
        ).all()
        
        # Count interactions by date
        interaction_counts = {}
        
        for interaction in interactions:
            date_key = interaction.timestamp.strftime(groupby_format)
            if date_key in interaction_counts:
                interaction_counts[date_key] += 1
            else:
                interaction_counts[date_key] = 1
        
        # Format for charts
        if period == 'week':
            days = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']
            labels = days
            data = [interaction_counts.get(str(i), 0) for i in range(7)]
        elif period == 'month':
            # Last 4 weeks
            week_numbers = [(datetime.now() - timedelta(days=7*i)).strftime(groupby_format) for i in range(4)]
            labels = [f'Week {w}' for w in week_numbers]
            data = [interaction_counts.get(w, 0) for w in week_numbers]
        elif period == 'year':
            # Last 12 months
            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
            current_month = datetime.now().month
            labels = [month_names[((current_month-i-1) % 12)] for i in range(12)]
            labels.reverse()
            
            months = [str(((current_month-i-1) % 12) + 1).zfill(2) for i in range(12)]
            months.reverse()
            data = [interaction_counts.get(m, 0) for m in months]
        
        return {
            'labels': labels,
            'data': data
        }
    
    def get_interaction_methods(self):
        """
        Get distribution of interaction methods.
        
        Returns:
            dict: Labels and data for charting
        """
        if not self.user_id:
            return {'labels': [], 'data': []}
        
        # Get all interactions for the user
        interactions = UserInteraction.query.filter_by(user_id=self.user_id).all()
        
        # Count by interaction type
        method_counts = {
            'text': 0,
            'gesture': 0,
            'symbol': 0,
            'eye': 0,
            'sound': 0
        }
        
        for interaction in interactions:
            if not interaction.text:
                continue
                
            if interaction.text.startswith('symbol:'):
                method_counts['symbol'] += 1
            elif interaction.text.startswith('gesture:'):
                method_counts['gesture'] += 1
            elif interaction.text.startswith('eye:'):
                method_counts['eye'] += 1
            elif interaction.text.startswith('sound:'):
                method_counts['sound'] += 1
            else:
                method_counts['text'] += 1
        
        # Ensure we have some data for visualization purposes
        # Production systems would remove this
        total = sum(method_counts.values())
        if total == 0:
            # Generate some initial data for demonstration
            method_counts['text'] = 7
            method_counts['gesture'] = 5
            method_counts['symbol'] = 4
            method_counts['eye'] = 2
            method_counts['sound'] = 1
        
        return {
            'labels': list(method_counts.keys()),
            'data': list(method_counts.values())
        }
    
    def get_learning_progress(self):
        """
        Calculate learning progress metrics.
        
        Returns:
            dict: Progress metrics
        """
        if not self.user_id:
            return {
                'vocabulary_growth': 0,
                'vocabulary_percentage': 0,
                'expression_growth': 0,
                'expression_percentage': 0,
                'multimodal_growth': 0,
                'multimodal_percentage': 0
            }
        
        # Get all interactions
        all_interactions = UserInteraction.query.filter_by(user_id=self.user_id).all()
        
        # Calculate metrics
        # 1. Vocabulary growth
        vocabulary = set()
        recent_vocabulary = set()
        
        # 2. Expression clarity (confidence scores)
        confidence_scores = []
        recent_confidence_scores = []
        
        # 3. Multimodal usage
        interaction_types = []
        recent_interaction_types = []
        
        # Cutoff date for recent data (last 2 weeks)
        recent_cutoff = datetime.now() - timedelta(days=14)
        
        for interaction in all_interactions:
            if not interaction.text:
                continue
                
            # Get base content without prefix
            content = interaction.text
            if ":" in content:
                parts = content.split(":", 1)
                if len(parts) > 1:
                    content = parts[1].strip()
            
            # Add to vocabulary sets
            if content:
                vocabulary.add(content.lower())
                if interaction.timestamp >= recent_cutoff:
                    recent_vocabulary.add(content.lower())
            
            # Add to confidence scores
            if interaction.confidence:
                confidence_scores.append(interaction.confidence)
                if interaction.timestamp >= recent_cutoff:
                    recent_confidence_scores.append(interaction.confidence)
            
            # Add to interaction types
            interaction_type = 'text'
            if interaction.text.startswith('symbol:'):
                interaction_type = 'symbol'
            elif interaction.text.startswith('gesture:'):
                interaction_type = 'gesture'
            elif interaction.text.startswith('eye:'):
                interaction_type = 'eye'
            elif interaction.text.startswith('sound:'):
                interaction_type = 'sound'
            
            interaction_types.append(interaction_type)
            if interaction.timestamp >= recent_cutoff:
                recent_interaction_types.append(interaction_type)
        
        # For a real application, these would be calculated from long-term historical data
        # For demonstration, we'll use placeholder calculations
        
        # 1. Vocabulary growth (% increase in unique expressions)
        vocabulary_count = len(vocabulary)
        recent_vocabulary_count = len(recent_vocabulary)
        vocabulary_growth = 15  # Sample growth %
        vocabulary_percentage = min(100, max(0, vocabulary_count * 5))  # Scale for demo
        
        if vocabulary_count > 0:
            # Calculate actual growth if we have enough data
            old_vocabulary_count = vocabulary_count - recent_vocabulary_count
            if old_vocabulary_count > 0:
                vocabulary_growth = int((recent_vocabulary_count / old_vocabulary_count - 1) * 100)
        
        # 2. Expression clarity (confidence improvement)
        avg_confidence = np.mean(confidence_scores) if confidence_scores else 0.5
        recent_avg_confidence = np.mean(recent_confidence_scores) if recent_confidence_scores else 0.5
        expression_growth = 8  # Sample growth %
        expression_percentage = min(100, max(0, int(avg_confidence * 100)))
        
        if avg_confidence > 0:
            # Calculate actual growth if we have enough data
            old_avg_confidence = avg_confidence
            if old_avg_confidence > 0:
                expression_growth = int((recent_avg_confidence / old_avg_confidence - 1) * 100)
        
        # 3. Multimodal usage (variety of input methods)
        unique_types = len(set(interaction_types))
        recent_unique_types = len(set(recent_interaction_types))
        multimodal_growth = 23  # Sample growth %
        multimodal_percentage = min(100, max(0, unique_types * 20))  # Scale for demo
        
        # If we have real data, calculate growth
        if len(interaction_types) > len(recent_interaction_types) and unique_types > 0:
            old_unique_types = unique_types - recent_unique_types
            if old_unique_types > 0:
                multimodal_growth = int((recent_unique_types / old_unique_types - 1) * 100)
        
        return {
            'vocabulary_growth': vocabulary_growth,
            'vocabulary_percentage': vocabulary_percentage,
            'expression_growth': expression_growth,
            'expression_percentage': expression_percentage,
            'multimodal_growth': multimodal_growth,
            'multimodal_percentage': multimodal_percentage
        }
    
    def get_frequent_expressions(self, limit=10):
        """
        Get most frequently used expressions.
        
        Args:
            limit (int): Maximum number of expressions to return
            
        Returns:
            list: Frequent expressions with counts
        """
        if not self.user_id:
            return []
        
        # Get all interactions
        interactions = UserInteraction.query.filter_by(user_id=self.user_id).all()
        
        # Extract expressions
        expressions = []
        for interaction in interactions:
            if not interaction.text:
                continue
                
            # Get base content without prefix
            content = interaction.text
            if ":" in content:
                parts = content.split(":", 1)
                if len(parts) > 1:
                    content = parts[1].strip()
            
            if content:
                expressions.append(content)
        
        # Count frequencies
        counter = Counter(expressions)
        
        # Convert to list and sort
        frequent_expressions = [{'text': text, 'count': count} for text, count in counter.most_common(limit)]
        
        return frequent_expressions
    
    def generate_system_suggestions(self):
        """
        Generate AI system suggestions based on user behavior patterns.
        
        Returns:
            list: System suggestions
        """
        if not self.user_id:
            return []
        
        # Get communication profile
        from models import CommunicationProfile
        profile = CommunicationProfile.get_latest_profile(self.user_id)
        
        # Get interactions
        interactions = UserInteraction.query.filter_by(user_id=self.user_id).all()
        
        # Analyze patterns
        interaction_types = []
        intent_counts = {}
        expression_counts = {}
        
        for interaction in interactions:
            # Track input modality
            interaction_type = 'text'
            if interaction.text:
                if interaction.text.startswith('symbol:'):
                    interaction_type = 'symbol'
                elif interaction.text.startswith('gesture:'):
                    interaction_type = 'gesture'
                elif interaction.text.startswith('eye:'):
                    interaction_type = 'eye'
                elif interaction.text.startswith('sound:'):
                    interaction_type = 'sound'
            
            interaction_types.append(interaction_type)
            
            # Track intent usage
            if interaction.intent:
                if interaction.intent in intent_counts:
                    intent_counts[interaction.intent] += 1
                else:
                    intent_counts[interaction.intent] = 1
        
        # Generate suggestions
        suggestions = []
        
        # Communication mode suggestions
        modality_counter = Counter(interaction_types)
        primary_mode = modality_counter.most_common(1)[0][0] if modality_counter else 'text'
        
        # If profile doesn't match primary mode, suggest update
        if profile and profile.primary_mode != primary_mode:
            suggestions.append({
                'title': f'Update Communication Profile',
                'description': f'User primarily communicates using {primary_mode} mode. Consider updating their primary communication mode setting.',
                'suggestion_type': 'profile',
                'confidence': 0.85
            })
        
        # Suggest adding symbols for frequent intents
        if intent_counts and 'symbol' not in modality_counter:
            top_intent = max(intent_counts.items(), key=lambda x: x[1])[0]
            suggestions.append({
                'title': 'Try Symbol-Based Communication',
                'description': f'User frequently expresses "{top_intent}" intent. Consider introducing symbols for this intent to potentially enhance communication.',
                'suggestion_type': 'communication',
                'confidence': 0.75
            })
        
        # Suggest emotional context settings
        if any(intent in intent_counts for intent in ['express_joy', 'express_sadness', 'express_anger']):
            suggestions.append({
                'title': 'Enable Emotional Context',
                'description': 'User expresses emotional content. Ensure emotional context processing is enabled for more natural communication.',
                'suggestion_type': 'setting',
                'confidence': 0.8
            })
        
        # Add more suggestions based on other patterns
        # (limited to a few examples for this implementation)
        
        return suggestions
    
    @classmethod
    def generate_mock_interaction(cls, user_id, text=None, intent=None, confidence=None):
        """
        Generate a mock interaction for demonstration purposes.
        
        Args:
            user_id (int): User ID
            text (str, optional): Interaction text
            intent (str, optional): Intent
            confidence (float, optional): Confidence score
            
        Returns:
            UserInteraction: Created interaction
        """
        from models import UserInteraction
        
        # Default values
        if text is None:
            # Generate a simple interaction
            options = [
                "I want water",
                "Help me please",
                "I'm feeling happy",
                "I don't like that",
                "symbol:food",
                "symbol:drink",
                "gesture:nod",
                "gesture:shake"
            ]
            text = np.random.choice(options)
        
        if intent is None:
            if text.startswith("symbol:"):
                intent = "communicate_symbol"
            elif text.startswith("gesture:"):
                intent = "communicate_gesture"
            else:
                options = ["request", "inform", "express", "acknowledge", "question"]
                intent = np.random.choice(options)
        
        if confidence is None:
            confidence = np.random.uniform(0.6, 0.95)
        
        # Create and save interaction
        interaction = UserInteraction(
            user_id=user_id,
            text=text,
            intent=intent,
            confidence=confidence,
            timestamp=datetime.now() - timedelta(days=np.random.randint(0, 30), 
                                               hours=np.random.randint(0, 24))
        )
        
        db.session.add(interaction)
        db.session.commit()
        
        return interaction
    
    @classmethod
    def generate_demo_data(cls, user_id, count=50):
        """
        Generate demo data for a new user.
        
        Args:
            user_id (int): User ID
            count (int): Number of interactions to generate
            
        Returns:
            list: Generated interactions
        """
        interactions = []
        
        # Sample data patterns
        modalities = ['text', 'symbol', 'gesture', 'eye', 'sound']
        modality_weights = [0.4, 0.3, 0.2, 0.05, 0.05]
        
        symbols = ['food', 'drink', 'bathroom', 'happy', 'sad', 'tired', 'help', 'yes', 'no']
        gestures = ['nod', 'shake', 'point_up', 'wave', 'thumbs_up', 'thumbs_down', 'open_palm']
        
        text_phrases = [
            "I want water",
            "Help me please",
            "I'm feeling happy",
            "I don't like that",
            "I need help",
            "I'm hungry",
            "I'm thirsty",
            "I'm tired",
            "Thank you",
            "Stop please"
        ]
        
        for i in range(count):
            # Choose modality
            modality = np.random.choice(modalities, p=modality_weights)
            
            # Generate text based on modality
            if modality == 'text':
                text = np.random.choice(text_phrases)
                intent = "communicate"
            elif modality == 'symbol':
                symbol = np.random.choice(symbols)
                text = f"symbol:{symbol}"
                intent = f"symbol_{symbol}"
            elif modality == 'gesture':
                gesture = np.random.choice(gestures)
                text = f"gesture:{gesture}"
                intent = f"gesture_{gesture}"
            elif modality == 'eye':
                regions = ['top_left', 'top_right', 'bottom_left', 'bottom_right', 'center']
                region = np.random.choice(regions)
                text = f"eye:{region}"
                intent = f"eye_tracking"
            else:  # sound
                sounds = ['hum', 'click', 'soft', 'loud', 'distress']
                sound = np.random.choice(sounds)
                text = f"sound:{sound}"
                intent = f"vocalization"
            
            # Generate confidence (with slight improvement trend over time)
            days_ago = count - i
            base_confidence = 0.6 + (i / count) * 0.3  # Ranges from 0.6 to 0.9 over time
            confidence = min(0.98, max(0.5, base_confidence + np.random.uniform(-0.1, 0.1)))
            
            # Create timestamp (more recent interactions are newer)
            timestamp = datetime.now() - timedelta(days=days_ago, 
                                                hours=np.random.randint(0, 24),
                                                minutes=np.random.randint(0, 60))
            
            # Create interaction
            interaction = UserInteraction(
                user_id=user_id,
                text=text,
                intent=intent,
                confidence=confidence,
                timestamp=timestamp
            )
            
            db.session.add(interaction)
            interactions.append(interaction)
        
        # Create communication profile
        profile = CommunicationProfile(
            user_id=user_id,
            primary_mode='text',
            secondary_mode='symbol'
        )
        
        db.session.add(profile)
        
        # Create preferences
        preferences = [
            UserPreference(user_id=user_id, type='gesture_sensitivity', value='0.8', source='system'),
            UserPreference(user_id=user_id, type='response_speed', value='1.0', source='manual'),
            UserPreference(user_id=user_id, type='sound_sensitivity', value='0.7', source='system'),
            UserPreference(user_id=user_id, type='emotion_display', value='true', source='manual')
        ]
        
        for pref in preferences:
            db.session.add(pref)
        
        db.session.commit()
        
        return interactions